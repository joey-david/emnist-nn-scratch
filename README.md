# Neural Networks From Scratch — CUDA & Python Editions

This repository hosts a set of small, framework-free neural network projects that explore different workflows:

- **`cpp_neural_net/`** contains a brand new C++/CUDA implementation of the music metadata classifier. It mirrors the NumPy network used in the interactive music tool, but runs everything on the GPU with custom CUDA kernels.
- **`music/`** keeps the Python scripts and utilities for working with precomputed audio metadata (no live YouTube downloads in this tree).
- **`emnits/`** preserves the original EMNIST/BHMSDS character recogniser that was built entirely with NumPy for experimentation and benchmarking.

The emphasis of the repository is now on the CUDA path, with the Python projects kept for reference and comparison.

## Directory Layout
- `cpp_neural_net/` – CUDA MLP, CSV loader, and CLI for training/inference on the GTZAN-style feature dataset.
- `music/` – interactive Python CLI, feature extraction helpers, and example metadata under `dataset/`.
- `emnits/` – NumPy-based handwriting classifier, preprocessing utilities, saved weights, and datasets.

## CUDA Music Metadata Classifier
The CUDA implementation reproduces the two-hidden-layer network used by `music/interactive_music_classifier.py`:
- He-initialised dense layers sized (input × 32 × 16 × num_labels)
- ReLU activations, softmax output, and cross-entropy loss
- Custom CUDA kernels for linear layers, softmax, gradient propagation, and parameter updates
- CSV reader that honours the feature layout generated by the Python tooling (skips filename/length columns, normalises each feature column)

### Build & Run
Requirements: a CUDA-capable GPU and the CUDA toolkit 11.0+ available to CMake/NVCC.

```bash
cmake -S cpp_neural_net -B cpp_neural_net/build
cmake --build cpp_neural_net/build
./cpp_neural_net/build/music_cuda_nn \
    --dataset music/dataset/features_30_sec.csv \
    --epochs 40 \
    --lr 0.001
```

CLI flags:
- `--dataset` – path to the CSV metadata (defaults to `../music/dataset/features_30_sec.csv` relative to the executable)
- `--epochs`, `--lr`, `--hidden1`, `--hidden2` – training hyperparameters
- `--seed` – RNG seed for reproducibility

The executable prints epoch loss/accuracy and runs an inference pass on the first sample once training completes.

## Music Utilities (Python)
The original notebook-backed workflow lives in `music/`:
- `interactive_music_classifier.py` – interactive CLI that records or loads clips, computes spectral features, and classifies them with the NumPy network.
- `youtube_feature_extractor.py` – feature extraction script for offline metadata creation (kept for reference; the C++ path expects an already prepared CSV).

These scripts use the same feature definitions as the CUDA implementation, so datasets can be shared between both toolchains.

## EMNIST Character Network
The EMNIST/BHMSDS experiments now live in `emnits/`:
- `dataset.py` – preprocessing pipeline for EMNIST and symbol datasets (paths resolve relative to the module).
- `neural_network.py` – NumPy implementation of the character MLP with early stopping and weight caching.
- `nn_tweaking.py` – hyperparameter sweeps and visualisation utilities.

Saved weights remain under `emnits/models/`, and raw/processed data are under `emnits/data/`.

## Next Steps
- Benchmark CUDA vs. NumPy training runs on the same metadata to quantify the speed-up.
- Extend the CUDA project with mini-batch training or cuBLAS-powered layers when additional performance is required.
- Integrate an export format (e.g. `.npz` or protobuf) so the Python tools can consume CUDA-trained weights.

Feel free to mix and match the components: the feature CSVs generated by the Python pipeline work out-of-the-box with the GPU classifier, making it easy to experiment with both worlds.
